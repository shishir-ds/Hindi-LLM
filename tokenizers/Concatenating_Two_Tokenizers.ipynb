{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce93f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ace9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"/data/Ghouse/tokenizers/HFT/tokenizer_hindi_freq50_bytelevel_v2.json\"\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "hindi_vocab = data['model']['vocab']\n",
    "hindi_merges = data['model']['merges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a51288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"/data/Ghouse/tokenizers/tokenizer_GPT2.json\"\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "gpt_vocab = data['model']['vocab']\n",
    "gpt_merges = data['model']['merges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fad85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_vocab = {}\n",
    "for token, token_id in hindi_vocab.items():\n",
    "        token = token.replace('\\n','n')\n",
    "        con_vocab[str(token)] = len(con_vocab)\n",
    "for token, token_id in gpt_vocab.items():\n",
    "    if token.replace('\\n','n') not in con_vocab.keys():\n",
    "        token = token.replace('\\n','n')\n",
    "        con_vocab[str(token)]=len(con_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f4dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "merges = []\n",
    "for merge in hindi_merges:\n",
    "    merges.append(merge)\n",
    "for merge in gpt_merges:\n",
    "    if merge not in merges:\n",
    "        merges.append(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdcb81cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 50257, 78456)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hindi_vocab), len(gpt_vocab), len(con_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e509ed24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29744, 50000, 78465)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hindi_merges), len(gpt_merges), len(merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e8a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"merges.txt\", \"w\", encoding=\"utf-8\") as merges_file:\n",
    "    for merge in merges:\n",
    "        merge = merge.replace('\\n', 'n')\n",
    "        merges_file.write(str(merge) + \"\\n\")\n",
    "with open(\"vocab.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(con_vocab, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d37f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_tokenizer = ByteLevelBPETokenizer(vocab=\"/data/Ghouse/vocab.json\", merges=\"/data/Ghouse/merges.txt\")\n",
    "\n",
    "con_tokenizer.save(\"/data/Ghouse/tokenizers/HFT/tokenizer_hindi_gpt2_Bytelevel_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "494351bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseTokenizer.get_vocab_size of Tokenizer(vocabulary_size=67481, model=ByteLevelBPE, add_prefix_space=False, lowercase=False, dropout=None, unicode_normalizer=None, continuing_subword_prefix=None, end_of_word_suffix=None, trim_offsets=False)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_tokenizer.get_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da22bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
